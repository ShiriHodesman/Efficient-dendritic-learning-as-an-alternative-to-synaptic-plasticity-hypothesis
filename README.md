The feedforward neural network comprised of 10 identifiers, each consisted of 784 inputs that were divided into groups of 16 consecutive pixels along the rows, one hidden layer consisted of 49 units and one output unit.
Each unit in the hidden and the output layers had an additional input from a bias unit. We denote by W 1 and W 2 the weights from the input layer to the hidden layer, and from the hidden layer to the output layer, respectively. The initial conditions of all weights were randomly chosen from a Gaussian distribution with a zero average and Std equals 1.
All weights to each hidden unit were normalized [2] such that they had a zero average and Std equals 1. 

